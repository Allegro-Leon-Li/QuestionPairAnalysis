{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cosine\n",
    "from nltk import word_tokenize\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load word2vec using gensim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_w2v = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df['question2'] = df['question2'].astype(str)\n",
    "df['question1'] = df['question1'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function for feature extraction based on rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stops = set(stopwords.words(\"english\"))\n",
    "\n",
    "def word_match_share(row):\n",
    "    q1words = {}\n",
    "    q2words = {}\n",
    "    for word in str(row['question1']).lower().split():\n",
    "        if word not in stops:\n",
    "            q1words[word] = 1\n",
    "    for word in str(row['question2']).lower().split():\n",
    "        if word not in stops:\n",
    "            q2words[word] = 1\n",
    "    if len(q1words) == 0 or len(q2words) == 0:\n",
    "        # The computer-generated chaff includes a few questions that are nothing but stopwords\n",
    "        return 0\n",
    "    shared_words_in_q1 = [w for w in q1words.keys() if w in q2words]\n",
    "    shared_words_in_q2 = [w for w in q2words.keys() if w in q1words]\n",
    "    R = (len(shared_words_in_q1) + len(shared_words_in_q2))/(len(q1words) + len(q2words))\n",
    "    return R\n",
    "\n",
    "def w2v_get(words):\n",
    "    cleaned = [w for w in words if w in model_w2v.vocab]\n",
    "    try:\n",
    "        res = np.mean(model_w2v[cleaned], axis=0)\n",
    "    except:\n",
    "        res = np.zeros(300)\n",
    "    return res\n",
    "\n",
    "\n",
    "def w2v_distance(row):\n",
    "    q1v = w2v_get(word_tokenize(row.question1))\n",
    "    q2v = w2v_get(word_tokenize(row.question2))\n",
    "    return cosine(q1v, q2v)\n",
    "\n",
    "def w2v_distance2(row):\n",
    "    q1 = word_tokenize(row.question1)\n",
    "    q2 = word_tokenize(row.question2)\n",
    "    return model_w2v.wmdistance(q1, q2)\n",
    "\n",
    "\n",
    "def tfidf_dis(row):\n",
    "    try:\n",
    "        vectorizer = TfidfVectorizer(stop_words='english')\n",
    "        vec = vectorizer.fit_transform([row['question1'], row['question2']])\n",
    "        vec = vec.todense()\n",
    "        return cosine(vec[0], vec[1])\n",
    "    except:\n",
    "        return 1.0\n",
    "\n",
    "def jaccard(row):\n",
    "    s1 = set(row['question1'])\n",
    "    s2 = set(row['question2'])\n",
    "    return 1 - (len(s1.intersection(s2)) / len(s1.union(s2)))\n",
    "\n",
    "def len_diff(row):\n",
    "    l1 = len(row['question1'])\n",
    "    l2 = len(row['question2'])\n",
    "    return abs(l1 - l2) / (l1 + l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/allegro_l/anaconda3/lib/python3.6/site-packages/scipy/spatial/distance.py:505: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - np.dot(u, v) / (norm(u) * norm(v))\n"
     ]
    }
   ],
   "source": [
    "df['w2v_dist'] = df.apply(w2v_distance, axis=1)\n",
    "df['w2v_dist2'] = df.apply(w2v_distance2, axis=1)\n",
    "df['tfidf_dist'] = df.apply(tfidf_dis, axis=1)\n",
    "df['jaccard_dist'] = df.apply(jaccard, axis=1)\n",
    "df['len_diff'] = df.apply(len_diff, axis=1)\n",
    "df['word_share'] = df.apply(word_match_share, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>w2v_dist</th>\n",
       "      <th>w2v_dist2</th>\n",
       "      <th>tfidf_dist</th>\n",
       "      <th>jaccard_dist</th>\n",
       "      <th>len_diff</th>\n",
       "      <th>word_share</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.042931</td>\n",
       "      <td>0.470209</td>\n",
       "      <td>0.104468</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.314483</td>\n",
       "      <td>2.118396</td>\n",
       "      <td>0.525669</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.266187</td>\n",
       "      <td>0.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.229717</td>\n",
       "      <td>1.991613</td>\n",
       "      <td>0.774235</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.106061</td>\n",
       "      <td>0.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.520283</td>\n",
       "      <td>3.080408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "      <td>0.320830</td>\n",
       "      <td>2.409782</td>\n",
       "      <td>0.793916</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.321739</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  w2v_dist  \\\n",
       "0  What is the step by step guide to invest in sh...             0  0.042931   \n",
       "1  What would happen if the Indian government sto...             0  0.314483   \n",
       "2  How can Internet speed be increased by hacking...             0  0.229717   \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  0.520283   \n",
       "4            Which fish would survive in salt water?             0  0.320830   \n",
       "\n",
       "   w2v_dist2  tfidf_dist  jaccard_dist  len_diff  word_share  \n",
       "0   0.470209    0.104468      0.000000  0.073171    0.727273  \n",
       "1   2.118396    0.525669      0.375000  0.266187    0.307692  \n",
       "2   1.991613    0.774235      0.300000  0.106061    0.363636  \n",
       "3   3.080408    1.000000      0.575758  0.130435    0.000000  \n",
       "4   2.409782    0.793916      0.333333  0.321739    0.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set training set and validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df[['w2v_dist', 'w2v_dist2', 'tfidf_dist', 'jaccard_dist', 'len_diff','word_share']]\n",
    "y_train = df['is_duplicate']\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.2, random_state=4242)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use XGBoost to train the binary classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.68218\tvalid-logloss:0.682283\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "[10]\ttrain-logloss:0.600555\tvalid-logloss:0.601491\n",
      "[20]\ttrain-logloss:0.550806\tvalid-logloss:0.552397\n",
      "[30]\ttrain-logloss:0.518355\tvalid-logloss:0.520375\n",
      "[40]\ttrain-logloss:0.496495\tvalid-logloss:0.498773\n",
      "[50]\ttrain-logloss:0.481461\tvalid-logloss:0.483934\n",
      "[60]\ttrain-logloss:0.470818\tvalid-logloss:0.473504\n",
      "[70]\ttrain-logloss:0.463094\tvalid-logloss:0.465958\n",
      "[80]\ttrain-logloss:0.457482\tvalid-logloss:0.460474\n",
      "[90]\ttrain-logloss:0.453445\tvalid-logloss:0.456554\n",
      "[100]\ttrain-logloss:0.450511\tvalid-logloss:0.453736\n",
      "[110]\ttrain-logloss:0.448144\tvalid-logloss:0.45146\n",
      "[120]\ttrain-logloss:0.446187\tvalid-logloss:0.449612\n",
      "[130]\ttrain-logloss:0.444642\tvalid-logloss:0.448153\n",
      "[140]\ttrain-logloss:0.443297\tvalid-logloss:0.44688\n",
      "[150]\ttrain-logloss:0.44228\tvalid-logloss:0.44592\n",
      "[160]\ttrain-logloss:0.441391\tvalid-logloss:0.4451\n",
      "[170]\ttrain-logloss:0.440615\tvalid-logloss:0.444371\n",
      "[180]\ttrain-logloss:0.439974\tvalid-logloss:0.443771\n",
      "[190]\ttrain-logloss:0.439378\tvalid-logloss:0.443238\n",
      "[200]\ttrain-logloss:0.438806\tvalid-logloss:0.44273\n",
      "[210]\ttrain-logloss:0.438195\tvalid-logloss:0.442189\n",
      "[220]\ttrain-logloss:0.4376\tvalid-logloss:0.441663\n",
      "[230]\ttrain-logloss:0.436963\tvalid-logloss:0.441104\n",
      "[240]\ttrain-logloss:0.436355\tvalid-logloss:0.440578\n",
      "[250]\ttrain-logloss:0.435877\tvalid-logloss:0.440166\n",
      "[260]\ttrain-logloss:0.435437\tvalid-logloss:0.439775\n",
      "[270]\ttrain-logloss:0.434891\tvalid-logloss:0.439291\n",
      "[280]\ttrain-logloss:0.434444\tvalid-logloss:0.438901\n",
      "[290]\ttrain-logloss:0.433979\tvalid-logloss:0.438499\n",
      "[300]\ttrain-logloss:0.433639\tvalid-logloss:0.438231\n",
      "[310]\ttrain-logloss:0.433307\tvalid-logloss:0.43797\n",
      "[320]\ttrain-logloss:0.433029\tvalid-logloss:0.437742\n",
      "[330]\ttrain-logloss:0.432772\tvalid-logloss:0.437561\n",
      "[340]\ttrain-logloss:0.432478\tvalid-logloss:0.437313\n",
      "[350]\ttrain-logloss:0.432169\tvalid-logloss:0.437072\n",
      "[360]\ttrain-logloss:0.431926\tvalid-logloss:0.436889\n",
      "[370]\ttrain-logloss:0.431674\tvalid-logloss:0.436686\n",
      "[380]\ttrain-logloss:0.43139\tvalid-logloss:0.436459\n",
      "[390]\ttrain-logloss:0.43117\tvalid-logloss:0.436285\n"
     ]
    }
   ],
   "source": [
    "# Set our parameters for xgboost\n",
    "params = {}\n",
    "params['objective'] = 'binary:logistic'\n",
    "params['eval_metric'] = 'logloss'\n",
    "params['eta'] = 0.03\n",
    "params['max_depth'] = 4\n",
    "\n",
    "d_train = xgb.DMatrix(x_train, label=y_train)\n",
    "d_valid = xgb.DMatrix(x_valid, label=y_valid)\n",
    "\n",
    "watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "\n",
    "bst = xgb.train(params, d_train, 400, watchlist, early_stopping_rounds=50, verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Deprecated\n",
    "\n",
    "def w2v_distance(q1, q2):\n",
    "    q1v = w2v_get(q1)\n",
    "    q2v = w2v_get(q2)\n",
    "    return cosine(q1v, q2v)\n",
    "\n",
    "df['w2v_dist'] = np.nan\n",
    "for i, row in df.iterrows():\n",
    "    q1 = word_tokenize(row.question1)\n",
    "    q2 = word_tokenize(row.question2)\n",
    "    df.set_value(i,'w2v_dist',w2v_distance(q1, q2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
